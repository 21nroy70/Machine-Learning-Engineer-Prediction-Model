---
title: "Fetch Take Home Assignment R Markdown Part 2"
author: "Nikhil Roy"
date: "December 1, 2023"
output: html_document
---

### What Are We Doing Here:

> We will finally use the prior to help us now! We will perform the Bayesian analysis using the Laplace Approximation. We will define the log-posterior function after we create the required information. This list we will need to include is the observed response, the design matrix, and the prior specification. Here, we will use independent Gaussian priors on the regression parameters with a shared prior mean and shared prior standard deviation. This is because this is a regression problem where the variables are continious and we are working with a continous predictor as well. Likewise, we will use an Exponential prior on the unknown likelihood noise (the $\sigma$ parameter).  

> First, we need to find our posterior mode and standard deviation which we need to use laplace approximixation in order to do so. This is a major step before diving into our machine learning algorithms to predict 2022 data - because the prior helps us a lot and tells us a lot for the log posterior. 


#### Load Libraries and read in data from part 1

```{r,message = FALSE}
library(tidyverse)
```


```{r,message = FALSE}
# Read in data and show what it looks 
scanned_df <- readr::read_csv("data_daily.csv", col_names = TRUE)
colnames(scanned_df)[1] ="Date"

#add columns to transform data to make it easier, cleaner, and more convenient to see and interpret
scanned_df <- scanned_df %>%
  mutate(Receipt_Count_Millions = Receipt_Count / 1e6,
         Day_of_Year = yday(as.Date(Date)))

scanned_df %>% glimpse()
```




> Since we do not know the prior mean and sd, we will calculate that based on our prior data given in 2021. Since I am not given any info or beliefs on the mean or standard deviation, we will use a 95% uncertainty intveral to found the lower and upper bound of our data. 

```{r}
mean_value <- mean(scanned_df$Receipt_Count_Millions)
sd_value <- sd(scanned_df$Receipt_Count_Millions)
sample_size <- length(scanned_df$Receipt_Count_Millions)

# Calculate the standard error
se <- sd_value / sqrt(sample_size)

# Calculate the margin of error
margin_of_error <- qt((1 + 0.95) / 2, df = sample_size - 1) * se

# Calculate the confidence interval
lower_bound <- round(mean_value - margin_of_error, 4)
upper_bound <- round(mean_value + margin_of_error, 4)

cat("95% Confidence Interval For The Mean: [", lower_bound, ",", upper_bound, "]\n")
```


> Using the values above in the interval, we feel there is approximately 95% probability the mean would be between values of 8.4761 and 8.9071.  


> We will use a Gaussian prior on the unknown mean. The prior distribution on the unknown mean, $\mu$, will have prior mean, $\mu_0$, and prior standard deviation, $\tau_0$. The prior on $\mu$ is therefore:

$$ 
\mu \mid \mu_0, \tau_0 \sim \mathrm{normal} \left( \mu \mid \mu_0, \tau_0 \right)
$$

For a Gaussian, the median equals the mode which equals the mean. The "$\pm2$ sigma" rule states that about 95% of the probability mass is contained with $\pm2$ standard deviations around the mean. We can therefore write that the lower end of the interval is equal to:

$$ 
\mu_0 - 2\times \tau_0 = 8.4761
$$

While the upper end of the interval is equal to:  

$$ 
\mu_0 + 2 \times \tau_0 = 8.9071.
$$
We therefore have 2 equations and 2 unknowns. Using the first relationship, we can write:  

$$ 
\mu_0 = 8.4761 + 2\times \tau_0
$$

Substituting into the second relationship gives:  

$$ 
8.4761 + 2\times \tau_0 + 2 \times \tau_0 = 8.4761 + 4 \times \tau_0= 8.9071.
$$

Rearrange:  

$$ 
4 \times \tau_0 = 8.9071. - 8.4761 = 0.431
$$

The prior standard deviation, $\tau_0$, on the unknown mean, $\mu$, is therefore:  

$$ 
\tau_0 = \frac{0.431}{4} = 0.10775
$$
Substituting back into the expression for the prior mean, $\mu_0$, gives:  

$$ 
\mu_0 = 8.4761 + 2\times (0.10775) = 8.6916
$$
$$
\mu_0 = 8.6916
$$

$$
\tau_0 = 0.10775
$$
The prior on the $\mu$ is therefore a Gaussian with prior mean equal to approximately 8.6916 and a prior standard deviation of 0.10775  

$$ 
\mu \mid \mu_0, \tau_0 \sim \mathrm{normal} \left( \mu \mid 8.6916, 0.10775 \right)
$$


Since there are specifications and restrictions or specififc instructions on the prior, we will treat the joint prior on $\mu$ and $\sigma$ as independent, $p\left(\mu,\sigma\right)=p\left(\mu\right)\times p\left(\sigma\right)$. The prior on the noise is assumed to be an Exponential distribution with a prior rate of 0.25, $\lambda = 0.25$.  

The un-normalized posterior on the two unknowns, $\mu$ and $\sigma$, is therefore:  

$$ 
p \left( \mu, \sigma \mid \mathbf{x} \right) \propto \prod_{n=1}^{N} \left( \mathrm{normal} \left(x_n \mid \mu, \sigma \right) \right) \times \mathrm{normal}\left(\mu \mid \mu_0, \tau_0\right) \times \mathrm{Exp}\left(\sigma \mid \lambda=0.25\right)
$$


```{r, eval=TRUE}
scanned_info <- list(
  xobs = scanned_df$Day_of_Year, ### the measurements
  mu_0 = 8.6916, ### mu_0 value
  tau_0 = 0.10775, ### tau_0 value
  sigma_rate = 0.25 ### rate (lambda) on sigma
)
```


> Now that we have our calculated prior mean and sd, we can finally visualize and find the posterior mean and standard deviation based upon on the prior. This is a crucial step before we get into the machine learning and predictions because we need to be sure of the posterior mode - which is another term for the posterior mean with the influence on the prior. We have the prior meana and standard deviation. Now, we need to use this in order to find and optimize our actual posterior mean and standard deviation. 

> We will define the log-posterior function based on the equations, data, and unknowns:


> We will now define the log-posterior function `lm_logpost()`. Here, we will continue to use the log-transformation on $\sigma$, and so we will actually define the log-posterior in terms of the mean trend $\boldsymbol{\beta}$-parameters and the unbounded noise parameter, $\varphi = \log\left[\sigma\right]$.  

```{r, eval=TRUE}
my_cv_logpost <- function(unknowns, my_info)
{
  # unpack the unknowns into separate variables
  lik_mu <- unknowns[1]
  lik_varphi <- unknowns[2]
  
  # back transform to sigma
  lik_sigma <- exp(lik_varphi)
  
  # calculate the log-likelihood
  log_lik <- sum(dnorm(x = my_info$xobs,
                       mean = lik_mu,
                       sd = lik_sigma,
                       log = TRUE))
  
  # calculate the log-prior on mu
  log_prior_mu <- dnorm(x = lik_mu,
                        mean = my_info$mu_0,
                        sd = my_info$tau_0,
                        log = TRUE)
  
  # calculate the log-prior on sigma
  log_prior_sigma <- dexp(x = lik_sigma,
                          rate = my_info$sigma_rate,
                          log = TRUE)
  
  # calculate the log-derivative adjustment
  log_deriv_adjust <- lik_varphi
  
  # return the (un-normalized) log-posterior
  log_lik + log_prior_mu + log_prior_sigma + log_deriv_adjust
}

```


> We will now find the posterior mode (the MAP) on the $\mu$ and $\varphi$ parameters based on using Laplace Optimization through optim(), First, we need to set up some functions and variables. 

```{r}
init_guess_01 <- c(10, 0.25) #mean 10, sd 0.5 as our initial guess
```


```{r}
map_res_01 <- optim(init_guess_01,
                    my_cv_logpost,
                    gr = NULL,
                    scanned_info,
                    method = "BFGS",
                    hessian = TRUE,
                    control = list(fnscale = -1, maxit = 1001))
```

> We found the posterior values, let's see what they are:

```{r}
map_res_01
```

> We can see the output but let's extract it and find the values and explain what they mean.

> First, what are the posterior mode and standard deviation:

```{r}
post_mean <- map_res_01$par[1]
post_sd <- sqrt(diag(-solve(map_res_01$hessian[1])))


cat("Posterior Mean: ", post_mean, "\nPosterior Standard Deviation: ", post_sd)

```


>Finding the posterior mode is the first step in the Laplace Approximation. The second step uses the negative inverse of the Hessian matrix as the approximate posterior covariance matrix. You wil use a function, `my_laplace()`, to perform the complete Laplace Approximation. This one function is all that is needed to perform all steps of the Laplace Approximation.  

```{r}
lm_logpost <- function(unknowns, my_info)
{
  # specify the number of unknown beta parameters
  length_beta <- ncol(my_info$design_matrix)
  
  # extract the beta parameters from the `unknowns` vector
  beta_v <- unknowns[1:length_beta]
  
  # extract the unbounded noise parameter, varphi
  lik_varphi <- unknowns[length_beta + 1]
  
  # back-transform from varphi to sigma
  lik_sigma <- exp(lik_varphi)
  
  # extract design matrix
  X <- my_info$design_matrix
  
  # calculate the linear predictor
  mu <- as.vector( X %*% as.matrix(beta_v) )
  
  # evaluate the log-likelihood
  log_lik <- sum(dnorm(x = my_info$yobs,
                       mean = mu,
                       sd = lik_sigma,
                       log = TRUE))
  
  # evaluate the log-prior
  log_prior_beta <- sum(dnorm(x = beta_v,
                              mean = my_info$mu_beta,
                              sd = my_info$tau_beta,
                              log = TRUE))
  
  log_prior_sigma <- dexp(x = lik_sigma,
                          rate = my_info$sigma_rate,
                          log = TRUE)
  
  # add the mean trend prior and noise prior together
  log_prior <- log_prior_beta + log_prior_sigma
  
  # account for the transformation
  log_derive_adjust <- lik_varphi
  
  # sum together
  log_lik + log_prior + log_derive_adjust
}
```



```{r, eval=TRUE}
my_laplace <- function(start_guess, logpost_func, ...)
{
  # code adapted from the `LearnBayes`` function `laplace()`
  fit <- optim(start_guess,
               logpost_func,
               gr = NULL,
               ...,
               method = "BFGS",
               hessian = TRUE,
               control = list(fnscale = -1, maxit = 1001))
  
  mode <- fit$par
  post_var_matrix <- -solve(fit$hessian)
  p <- length(mode)
  # we will discuss what int means in a few weeks...
  int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
  # package all of the results into a list
  list(mode = mode,
       var_matrix = post_var_matrix,
       log_evidence = int,
       converge = ifelse(fit$convergence == 0,
                         "YES", 
                         "NO"),
       iter_counts = as.numeric(fit$counts[1]))
}
```


```{r}
laplace_result <- my_laplace(init_guess_01, my_cv_logpost, scanned_info)
```

> We will now perform the Laplace Approximation to determine the approximate posterior on the $\mu$ and $\varphi$ parameters given the measurements.  


Print out the required posterior summary statistics on the parameters.  

```{r}
laplace_result$mode
```

```{r}
sqrt(diag(laplace_result$var_matrix))
```

```{r}
laplace_result$var_matrix[1, 2] / 
  (sqrt(laplace_result$var_matrix[1,1]) * sqrt(laplace_result$var_matrix[2,2]))
```


> So the Posterior Mode and standard deviation are:

```{r}
cat("Posterior Mean: ", post_mean, "\nPosterior Standard Deviation: ", post_sd)
```


> We have found the posterior mode and posterior standard deviation based on our prior data! This is huge. Now, we can start making posterior predictions now that we have information! Let's use model 1 and use our laplace approximation and optimization function I created earlier to help us identify and explain the posterior predictions on the model. 


> Since we are using model 1 for our selection, we will use 3 types of priors and see how they differ. The types of priors are: weak, strong, and very strong priors 

```{r}

X01 <-model.matrix(Receipt_Count_Millions ~ Day_of_Year, data = scanned_df)



info_03_weak <- list(
  yobs = scanned_df$Receipt_Count_Millions,
  design_matrix = X01,
  mu_beta = 8.71129,
  tau_beta = 50,
  sigma_rate = 0.1077438
)

info_03_strong <- list(
  yobs = scanned_df$Receipt_Count_Millions,
  design_matrix = X01,
  mu_beta = 8.71129,
  tau_beta = 1,
  sigma_rate = 0.1077438
)

info_03_very_strong <- list(
  yobs = scanned_df$Receipt_Count_Millions,
  design_matrix = X01,
  mu_beta = 8.71129,
  tau_beta = 0.02,
  sigma_rate = 0.1077438
)
```


```{r}
laplace_03_weak <- my_laplace(rep(0, ncol(X01)+1), lm_logpost, info_03_weak)
laplace_03_strong <- my_laplace(rep(0, ncol(X01)+1), lm_logpost, info_03_strong)
laplace_03_very_strong <- my_laplace(rep(0, ncol(X01)+1), lm_logpost, info_03_very_strong)

```


> The `generate_lm_post_samples()` function is defined down below. It uses the `MASS::mvrnorm()` function generate posterior samples from the Laplace Approximation's MVN distribution.  


```{r, make_lm_post_samples_func}
generate_lm_post_samples <- function(mvn_result, length_beta, num_samples)
{
  MASS::mvrnorm(n = num_samples,
                mu = mvn_result$mode,
                Sigma = mvn_result$var_matrix) %>% 
    as.data.frame() %>% tibble::as_tibble() %>% 
    purrr::set_names(c(sprintf("beta_%02d", 0:(length_beta-1)), "varphi")) %>% 
    mutate(sigma = exp(varphi))
}

```



> The code chunk below starts the `post_lm_pred_samples()` function. This function generates posterior mean trend predictions and posterior predictions of the response. The first argument, `Xnew`, is a potentially new or test design matrix that we wish to make predictions at. The second argument, `Bmat`, is a matrix of posterior samples of the $\boldsymbol{\beta}$-parameters, and the third argument, `sigma_vector`, is a vector of posterior samples of the likelihood noise. The `Xnew` matrix has rows equal to the number of predictions points, `M`, and the `Bmat` matrix has rows equal to the number of posterior samples `S`.  

> The `post_lm_pred_samples()` returns the `Umat` and `Ymat` matrices contained within a list.  

```{r, eval=TRUE}
post_lm_pred_samples <- function(Xnew, Bmat, sigma_vector)
{
  # number of new prediction locations
  M <- nrow(Xnew)
  # number of posterior samples
  S <- nrow(Bmat)
  
  # matrix of linear predictors
  Umat <- Xnew %*% t(Bmat)
  
  # assmeble matrix of sigma samples, set the number of rows
  Rmat <- matrix(rep(sigma_vector, M), M, byrow = TRUE)
  
  # generate standard normal and assemble into matrix
  # set the number of rows
  Zmat <- matrix(rnorm(M*S), M, byrow = TRUE)
  
  # calculate the random observation predictions
  Ymat <- Umat + Rmat * Zmat
  
  # package together
  list(Umat = Umat, Ymat = Ymat)
}
```

> We will summarize the posterior predictions to focus on the posterior means and the middle 95% uncertainty intervals. The code chunk below serves as a useful wrapper function to call `post_lm_pred_samples()`.  

```{r, make_the_lm_pred_func}
make_post_lm_pred <- function(Xnew, post)
{
  Bmat <- post %>% select(starts_with("beta_")) %>% as.matrix()
  
  sigma_vector <- post %>% pull(sigma)
  
  post_lm_pred_samples(Xnew, Bmat, sigma_vector)
}
```



> The code chunk below defines a function `summarize_lm_pred_from_laplace()` which manages the actions necessary to summarize posterior predictions. The first argument, `mvn_result`, is the Laplace Approximation object. The second object is the test design matrix, `Xtest`, and the third argument, `num_samples`, is the number of posterior samples to make.  

```{r, eval=TRUE}
summarize_lm_pred_from_laplace <- function(mvn_result, Xtest, num_samples)
{
  # generate posterior samples of the beta parameters
  post <- generate_lm_post_samples(mvn_result, ncol(Xtest), num_samples)
  
  # make posterior predictions on the test set
  pred_test <- make_post_lm_pred(Xtest, post)
  
  # calculate summary statistics on the predicted mean and response
  # summarize over the posterior samples
  
  # posterior mean, should you summarize along rows (rowMeans) or 
  # summarize down columns (colMeans) ???
  mu_avg <- rowMeans(pred_test$Umat)
  y_avg <- rowMeans(pred_test$Ymat)
  
  # posterior quantiles for the middle 95% uncertainty intervals
  mu_lwr <- apply(pred_test$Umat, 1, stats::quantile, probs = 0.025)
  mu_upr <- apply(pred_test$Umat, 1, stats::quantile, probs = 0.975)
  y_lwr <- apply(pred_test$Ymat, 1, stats::quantile, probs = 0.025)
  y_upr <- apply(pred_test$Ymat, 1, stats::quantile, probs = 0.975)
  
  # book keeping
  tibble::tibble(
    mu_avg = mu_avg,
    mu_lwr = mu_lwr,
    mu_upr = mu_upr,
    y_avg = y_avg,
    y_lwr = y_lwr,
    y_upr = y_upr
  ) %>% 
    tibble::rowid_to_column("pred_id")
}
```



> Create values from days 366 to 730 -> AKA year 2 -> AKA Year 2022. Using 365 evenly spaced values so 1 prediction per day are made, or a prediction for each day in the Year 2022. 

```{r}
viz_grid <- expand.grid(Day_of_Year = seq(366, 730, length.out = 365),
                        KEEP.OUT.ATTRS = FALSE
                        ) %>% 
  as.data.frame() %>% tibble::as_tibble()
```


> Test design matrix and the summarizing posterior predictions based on the 3 types of priors - weak, strong, very strong

```{r}
X03_test <- model.matrix( ~ Day_of_Year, data = viz_grid)



post_pred_summary_viz_03_weak <- summarize_lm_pred_from_laplace(laplace_03_weak, 
                                                                X03_test, 
                                                                5000)

post_pred_summary_viz_03_weak$Year_2022_Days <- post_pred_summary_viz_03_weak$pred_id


post_pred_summary_viz_03_strong <- summarize_lm_pred_from_laplace(laplace_03_strong, 
                                                                  X03_test, 
                                                                  5000)

post_pred_summary_viz_03_strong$Year_2022_Days <- post_pred_summary_viz_03_strong$pred_id 


post_pred_summary_viz_03_very_strong <- summarize_lm_pred_from_laplace(laplace_03_very_strong,
                                X03_test, 
                                5000)

post_pred_summary_viz_03_very_strong$Year_2022_Days <- post_pred_summary_viz_03_very_strong$pred_id

```


> Let's now visualize the posterior predictions from model 1 Bayesian models associated with the weak, strong, and very strong priors.


Weak prior onto posterior prediction

```{r, eval=TRUE}
post_pred_summary_viz_03_weak %>% 
  left_join(viz_grid %>% tibble::rowid_to_column("Year_2022_Days"),
            by = 'Year_2022_Days') %>% 
  ggplot(mapping = aes(x = Day_of_Year)) +
  geom_ribbon(mapping = aes(ymin = y_lwr,
                            ymax = y_upr),
              fill = 'orange') +
  geom_ribbon(mapping = aes(ymin = mu_lwr,
                            ymax = mu_upr),
              fill = 'grey') +
  geom_line(mapping = aes(y = mu_avg),
            color = 'black')+
  theme_bw()
```


Strong prior onto posterior prediction

```{r, eval=TRUE}
post_pred_summary_viz_03_strong %>% 
  left_join(viz_grid %>% tibble::rowid_to_column("Year_2022_Days"),
            by = 'Year_2022_Days') %>% 
  ggplot(mapping = aes(x = Day_of_Year)) +
  geom_ribbon(mapping = aes(ymin = y_lwr,
                            ymax = y_upr),
              fill = 'orange') +
  geom_ribbon(mapping = aes(ymin = mu_lwr,
                            ymax = mu_upr),
              fill = 'grey') +
  geom_line(mapping = aes(y = mu_avg),
            color = 'black')+
  theme_bw()
```


Very Strong prior onto posterior prediction

```{r, eval=TRUE}
post_pred_summary_viz_03_very_strong %>% 
  left_join(viz_grid %>% tibble::rowid_to_column("Year_2022_Days"),
            by = 'Year_2022_Days') %>% 
  ggplot(mapping = aes(x = Day_of_Year)) +
  geom_ribbon(mapping = aes(ymin = y_lwr,
                            ymax = y_upr),
              fill = 'orange') +
  geom_ribbon(mapping = aes(ymin = mu_lwr,
                            ymax = mu_upr),
              fill = 'grey') +
  geom_line(mapping = aes(y = mu_avg),
            color = 'black')+
  theme_bw()
```

> Conclusion:
> The affect on a weak vs. strong prior basically have no affect. That being said, when we have a very strong prior, such as the the 3rd plot, the predictions are very uncertain and the range is astronomically higher compared to the weak and strong prior. The confidence interval (in grey) is not even visible and incredibly smaller relative to the prediction interval (in orannge) because the very strong prior restricted the coefficients and thus prevented the trend from matching the observations. This drives up the error and thus increases the size of the prediction interval relative to the confidence interval.Even the scales on the Y-axis predictions are incredibly higher in the Billions, which is far unreasnable when you look at the 2021 data,  the prior values, and the posterior mode and standard deviation from the covariance matrix calculated from Heissen matrix. Thus, this is why we do not use and infer an uncertain or very strong prior. That being said, the weak and strong priors are very similar so using one of those would help us at making predictions for the 2022 data. 

>As you can see in the graphs, it is a linear increase with a positve correlation between the Days Of the Year and the Recipients Counts (In Millions). 


> Below Are the predictions made for the 2022 Year for the weak and strong priors. We already dicussed why we are not using the very_strong prior. They are saved in a df with just the 2022 date and the predicted value of recipients IN MILLIONS

```{r}
Year_2022_Predictions_Weak_Prior <- post_pred_summary_viz_03_weak %>% select(Year_2022_Days, mu_avg) %>% mutate(Year_2022_Days = Year_2022_Days,
                                        Predicted_Recipient_Count_In_Millions = mu_avg                                                                     )
Year_2022_Predictions_Weak_Prior <- Year_2022_Predictions_Weak_Prior %>% 
  select(-mu_avg)

Year_2022_Predictions_Weak_Prior %>% glimpse()
```




```{r}
Year_2022_Predictions_Strong_Prior <- post_pred_summary_viz_03_strong %>% select(Year_2022_Days, mu_avg) %>% mutate(Year_2022_Days = Year_2022_Days,
                                        Predicted_Recipient_Count_In_Millions = mu_avg                                                                     )
Year_2022_Predictions_Strong_Prior <- Year_2022_Predictions_Strong_Prior %>% 
  select(-mu_avg)

Year_2022_Predictions_Strong_Prior %>% glimpse()

```


> We have incoperated the priors, calculated and found both the posterior mean (posterior mode) and the posterior standard deviation that maximizes the function for our predictions amongst both the weak and strong priors for tau. We have concluded model 1 is the best model - a simple linear relationship between the date and recipient count. We have made predictions (as provided in the above data frames) based upon the days 366-730, which correspond to the next year - Year 2022 which we were asked to predict from the 2021 data that we were provided with. 



